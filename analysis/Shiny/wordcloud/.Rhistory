knitr::opts_chunk$set(echo = TRUE)
df = read_csv('cleaned_nyc_data.csv')
library(tidyverse)
library(rgeos)
library(geojsonio)
df = read_csv('cleaned_nyc_data.csv')
df = read_csv('cleaned_nyc_data.csv')
nyc_districts <- geojson_read(fil, what="sp")
nyc_districts <- geojson_read(nyc_community_districts.geojson, what="sp")
nyc_districts <- geojson_read("nyc_community_districts.geojson", what="sp")
nyc_districts_map <- fortify(nyc_districts, region="BoroCD")
nycmap <- ggplot() + geom_map(data=nyc_districts_map,
map=nyc_districts_map,
aes(x=long, y=lat, map_id=id),
color="black",
size=0.15,
fill=NA) +
coord_map() +
ggthemes::theme_map()
nycmap
library(tidyverse)
data = read.delim("listings.csv",sep = ",")
med = read_csv("NYC_median_sales_price_per_unit_1family_building2018.csv")
View(med)
data_cleaned = data[-c(1:39,42:48,51,60,62:63,68:77,82:86,94:98,100,101,103:105)]
data_cleaned[,1] = as.character(data_cleaned[,1])
data_cleaned[,13] = as.numeric(gsub("\\$", "", as.character(data_cleaned[,13])))
data_cleaned[,14] = as.numeric(gsub("\\$", "", as.character(data_cleaned[,14])))
data_cleaned[,15] = as.numeric(gsub("\\$", "", as.character(data_cleaned[,15])))
data_cleaned[,17] = as.numeric(gsub("\\$", "", as.character(data_cleaned[,17])))
write.csv(data_cleaned,'cleaned_nyc_data.csv', row.names=FALSE)
URL <- "http://services5.arcgis.com/GfwWNkhOj9bNBqoJ/arcgis/rest/services/nycd/FeatureServer/0/query?where=1=1&outFields=*&outSR=4326&f=geojson"
fil <- "nyc_community_districts.geojson"
if (!file.exists(fil)) download.file(URL, fil)
df = read_csv('cleaned_nyc_data.csv')
nyc_districts <- geojson_read("nyc_community_districts.geojson", what="sp")
nyc_districts_map <- fortify(nyc_districts, region="BoroCD")
nycmap <- ggplot() + geom_map(data=nyc_districts_map,
map=nyc_districts_map,
aes(x=long, y=lat, map_id=id),
color="black",
size=0.15,
fill=NA) +
coord_map() +
ggthemes::theme_map()
df = read_csv('cleaned_nyc_data.csv')
nyc_districts <- geojson_read("nyc_community_districts.geojson", what="sp")
nyc_districts_map <- fortify(nyc_districts, region="BoroCD")
nycmap <- ggplot() + geom_map(data=nyc_districts_map,
map=nyc_districts_map,
aes(x=long, y=lat, map_id=id),
color="black",
size=0.15,
fill=NA) +
coord_map() +
ggthemes::theme_map()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rgeos)
install.packages("rgeos")
library(tidyverse)
library(rgeos)
library(geojsonio)
install.packages("geojsonio")
install.packages("rsconnect")
install.packages("shiny")
library(geojsonio)
knitr::opts_chunk$set(echo = TRUE, alert = FALSE)
library(tidyverse)
library(rgeos)
library(geojsonio)
df = read_csv('cleaned_nyc_data.csv')
nyc_districts <- geojson_read("nyc_community_districts.geojson", what="sp")
nyc_districts_map <- fortify(nyc_districts, region="BoroCD")
nycmap <- ggplot() + geom_map(data=nyc_districts_map,
map=nyc_districts_map,
aes(x=long, y=lat, map_id=id),
color="black",
size=0.15,
fill=NA) +
coord_map() +
ggthemes::theme_map()
install.packages("ggthemes")
df = read_csv('cleaned_nyc_data.csv')
nyc_districts <- geojson_read("nyc_community_districts.geojson", what="sp")
nyc_districts_map <- fortify(nyc_districts, region="BoroCD")
nycmap <- ggplot() + geom_map(data=nyc_districts_map,
map=nyc_districts_map,
aes(x=long, y=lat, map_id=id),
color="black",
size=0.15,
fill=NA) +
coord_map() +
ggthemes::theme_map()
df = read_csv('cleaned_nyc_data.csv')
nyc_districts <- geojson_read("nyc_community_districts.geojson", what="sp")
nyc_districts_map <- fortify(nyc_districts, region="BoroCD")
nycmap <- ggplot() + geom_map(data=nyc_districts_map,
map=nyc_districts_map,
aes(x=long, y=lat, map_id=id),
color="black",
size=0.15,
fill=NA) +
coord_map() +
ggthemes::theme_map()
View(nyc_districts)
View(nyc_districts)
View(nyc_districts)
nycmap
df = read_csv('cleaned_nyc_data.csv')
nyc_districts <- geojson_read("nyc_community_districts.geojson", what="sp")
nyc_districts_map <- fortify(nyc_districts, region="BoroCD")
nycmap <- ggplot() + geom_map(data=nyc_districts_map,
map=nyc_districts_map,
aes(x=long, y=lat, map_id=id),
color="black",
size=0.15,
fill=NA) +
coord_map() +
ggthemes::theme_map()
nycmap
library(tidyverse)
library(rgeos)
library(geojsonio)
df = read_csv('cleaned_nyc_data.csv')
nyc_districts <- geojson_read("nyc_community_districts.geojson", what="sp")
nyc_districts_map <- fortify(nyc_districts, region="BoroCD")
nycmap <- ggplot() + geom_map(data=nyc_districts_map,
map=nyc_districts_map,
aes(x=long, y=lat, map_id=id),
color="black",
size=0.15,
fill=NA) +
coord_map() +
ggthemes::theme_map()
nycmap
nyc_data = read.csv("cleaned_nyc_data.csv")
View(nyc_data)
word = nyc_data$amenities
head(word, 10)
install.packages("tm")  # for text mining
install.packages("SnowballC") # for text stemming
install.packages("wordcloud") # word-cloud generator
install.packages("RColorBrewer") # color palettes
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
Corpus(word)
Corpus(VectorSource(word))
my_word <- Corpus(VectorSource(word))
# convert to lower case
my_word <- tm_map(my_word, content_transformer(tolower))
View(my_word)
# Remove punctuations
my_word <- tm_map(my_word, removePunctuation)
View(my_word)
#create a term matrix and store it as dtm
dtm <- TermDocumentMatrix(mydata)
#create a term matrix and store it as dtm
dtm <- TermDocumentMatrix(my_word)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
nyc_data = read.csv("cleaned_nyc_data.csv")
word = nyc_data$amenities
my_word <- Corpus(VectorSource(word))
inspect(my_word)
word = nyc_data$amenities
my_word <- Corpus(VectorSource(word))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
# convert to lower case
my_word <- tm_map(my_word, content_transformer(tolower))
# Remove punctuations
my_word <- tm_map(my_word, removePunctuation)
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
#create a term matrix and store it as dtm
dtm <- TermDocumentMatrix(my_word)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
word = nyc_data$amenities
my_word <- Corpus(VectorSource(word))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "{")
docs <- tm_map(docs, toSpace, ",")
docs <- tm_map(docs, toSpace, "}")
docs <- tm_map(docs, toSpace, "'")
# convert to lower case
my_word <- tm_map(my_word, content_transformer(tolower))
# Remove punctuations
my_word <- tm_map(my_word, removePunctuation)
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
#create a term matrix and store it as dtm
dtm <- TermDocumentMatrix(my_word)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
word = nyc_data$amenities
my_word <- Corpus(VectorSource(word))
toSpace <- content_transformer(function (x , pattern) gsub(pattern, " ", x))
my_word <- tm_map(my_word, toSpace, "/")
my_word <- tm_map(my_word, toSpace, "{")
my_word <- tm_map(my_word, toSpace, ",")
my_word <- tm_map(my_word, toSpace, "}")
my_word <- tm_map(my_word, toSpace, "'")
# convert to lower case
my_word <- tm_map(my_word, content_transformer(tolower))
# Remove punctuations
my_word <- tm_map(my_word, removePunctuation)
# Remove numbers
my_word <- tm_map(my_word, removeNumbers)
# Remove english common stopwords
my_word <- tm_map(my_word, removeWords, stopwords("english"))
#create a term matrix and store it as dtm
dtm <- TermDocumentMatrix(my_word)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
word = nyc_data$amenities
my_word <- Corpus(VectorSource(word))
toSpace <- content_transformer(function (x , pattern) gsub(pattern, " ", x))
my_word <- tm_map(my_word, toSpace, "/")
my_word <- tm_map(my_word, toSpace, "{")
my_word <- tm_map(my_word, toSpace, ",")
my_word <- tm_map(my_word, toSpace, "}")
my_word <- tm_map(my_word, toSpace, "'")
# convert to lower case
my_word <- tm_map(my_word, content_transformer(tolower))
# Remove punctuations
my_word <- tm_map(my_word, removePunctuation)
# Remove numbers
my_word <- tm_map(my_word, removeNumbers)
# Remove english common stopwords
my_word <- tm_map(my_word, removeWords, stopwords("english"))
my_word <- tm_map(my_word, removeWords, stopwords("friendly"))
my_word <- tm_map(my_word, removeWords, stopwords("hair"))
my_word <- tm_map(my_word, removeWords, stopwords("enhostingamenity"))
#create a term matrix and store it as dtm
dtm <- TermDocumentMatrix(my_word)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
View(nyc_data)
word = nyc_data$amenities
my_word <- Corpus(VectorSource(word))
toSpace <- content_transformer(function (x , pattern) gsub(pattern, " ", x))
my_word <- tm_map(my_word, toSpace, "/")
my_word <- tm_map(my_word, toSpace, "{")
my_word <- tm_map(my_word, toSpace, ",")
my_word <- tm_map(my_word, toSpace, "}")
my_word <- tm_map(my_word, toSpace, "'")
word = nyc_data$amenities
my_word <- Corpus(VectorSource(word))
toSpace <- content_transformer(function (x , pattern) gsub(pattern, " ", x))
my_word <- tm_map(my_word, toSpace, "/")
#my_word <- tm_map(my_word, toSpace, "{")
#my_word <- tm_map(my_word, toSpace, ",")
#my_word <- tm_map(my_word, toSpace, "}")
my_word <- tm_map(my_word, toSpace, "'")
# convert to lower case
my_word <- tm_map(my_word, content_transformer(tolower))
# Remove punctuations
my_word <- tm_map(my_word, removePunctuation)
# Remove numbers
my_word <- tm_map(my_word, removeNumbers)
# Remove english common stopwords
my_word <- tm_map(my_word, removeWords, stopwords("english"))
my_word <- tm_map(my_word, removeWords, stopwords("friendly"))
my_word <- tm_map(my_word, removeWords, stopwords("hair"))
my_word <- tm_map(my_word, removeWords, stopwords("enhostingamenity"))
#create a term matrix and store it as dtm
dtm <- TermDocumentMatrix(my_word)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
word = nyc_data$amenities
my_word <- Corpus(VectorSource(word))
toSpace <- content_transformer(function (x , pattern) gsub(pattern, " ", x))
my_word <- tm_map(my_word, toSpace, "/")
#my_word <- tm_map(my_word, toSpace, "{")
my_word <- tm_map(my_word, toSpace, ",")
#my_word <- tm_map(my_word, toSpace, "}")
my_word <- tm_map(my_word, toSpace, "'")
# convert to lower case
my_word <- tm_map(my_word, content_transformer(tolower))
# Remove punctuations
my_word <- tm_map(my_word, removePunctuation)
# Remove numbers
my_word <- tm_map(my_word, removeNumbers)
# Remove english common stopwords
my_word <- tm_map(my_word, removeWords, stopwords("english"))
my_word <- tm_map(my_word, removeWords, stopwords("friendly"))
my_word <- tm_map(my_word, removeWords, stopwords("hair"))
my_word <- tm_map(my_word, removeWords, stopwords("enhostingamenity"))
#create a term matrix and store it as dtm
dtm <- TermDocumentMatrix(my_word)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
inspect(my_word)
my_word[["1"]][["content"]]
nyc_data$amenities[1]
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
library(tidyverse)
library(rgeos)
library(geojsonio)
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library(memoise)
df2 <- read_csv("reviews.csv")
rm(list = ls())
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library(memoise)
reviews <- read.csv("~/Desktop/EDAV_FINAL_PROJECT/EDAV_final_project-master/reviews.csv", stringsAsFactors=FALSE)
reviews$date <- as.Date(reviews$date,format = "%m/%d/%y")
comments <- reviews[reviews$date > "2019-05-01",]
comments <- comments$comments
k = getTermMatrix(comments)
word = comments
my_word <- Corpus(VectorSource(word))
toSpace <- content_transformer(function (x , pattern) gsub(pattern, " ", x))
my_word <- tm_map(my_word, toSpace, "/")
#my_word <- tm_map(my_word, toSpace, "{")
my_word <- tm_map(my_word, toSpace, ",")
#my_word <- tm_map(my_word, toSpace, "}")
my_word <- tm_map(my_word, toSpace, "'")
# convert to lower case
my_word <- tm_map(my_word, content_transformer(tolower))
# Remove punctuations
my_word <- tm_map(my_word, removePunctuation)
# Remove numbers
my_word <- tm_map(my_word, removeNumbers)
# Remove english common stopwords
my_word <- tm_map(my_word, removeWords, stopwords("english"))
my_word <- tm_map(my_word, removeWords, stopwords("friendly"))
my_word <- tm_map(my_word, removeWords, stopwords("hair"))
my_word <- tm_map(my_word, removeWords, stopwords("enhostingamenity"))
#create a term matrix and store it as dtm
dtm <- TermDocumentMatrix(my_word)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
d
comments <- reviews[reviews$date > "2019-05-01",]
comments <- comments$comments
word = comments
my_word <- Corpus(VectorSource(word))
toSpace <- content_transformer(function (x , pattern) gsub(pattern, " ", x))
my_word <- tm_map(my_word, toSpace, "/")
#my_word <- tm_map(my_word, toSpace, "{")
my_word <- tm_map(my_word, toSpace, ",")
#my_word <- tm_map(my_word, toSpace, "}")
my_word <- tm_map(my_word, toSpace, "'")
# convert to lower case
my_word <- tm_map(my_word, content_transformer(tolower))
# Remove punctuations
my_word <- tm_map(my_word, removePunctuation)
# Remove numbers
my_word <- tm_map(my_word, removeNumbers)
# Remove english common stopwords
my_word <- tm_map(my_word, removeWords, stopwords("english"))
my_word <- tm_map(my_word, removeWords, stopwords("friendly"))
my_word <- tm_map(my_word, removeWords, stopwords("hair"))
my_word <- tm_map(my_word, removeWords, stopwords("enhostingamenity"))
#create a term matrix and store it as dtm
dtm <- TermDocumentMatrix(my_word)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library(memoise)
nyc_data = read.csv("cleaned_nyc_data.csv")
word = nyc_data$amenities
shiny::runApp('~/Desktop/EDAV_FINAL_PROJECT/Shiny/wordcloud')
View(dtm)
rm(list = ls())
runApp('~/Desktop/EDAV_FINAL_PROJECT/Shiny/wordcloud')
runApp('~/Desktop/EDAV_FINAL_PROJECT/Shiny/wordcloud')
runApp('~/Desktop/EDAV_FINAL_PROJECT/Shiny/wordcloud')
runApp('~/Desktop/EDAV_FINAL_PROJECT/Shiny/wordcloud')
